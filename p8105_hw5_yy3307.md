p8105_hw5_yy3307
================
2022-11-03

## Problem 1

The code chunk below imports the data in individual spreadsheets
contained in `./data`. To do this, I create a dataframe that includes
the list of all files in that directory and the complete path to each
file. As a next step, I `map` over paths and import data using the
`read_csv` function. Finally, I `unnest` the result of `map`.

``` r
full_df = 
  tibble(
    files = list.files("data/"),
    path = str_c("data/", files)
  ) %>% 
  mutate(data = map(path, read_csv)) %>% 
  unnest()
```

The result of the previous code chunk isn’t tidy – data are wide rather
than long, and some important variables are included as parts of others.
The code chunk below tides the data using string manipulations on the
file, converting from wide to long, and selecting relevant variables.

``` r
tidy_df = 
  full_df %>% 
  mutate(
    files = str_replace(files, ".csv", ""),
    group = str_sub(files, 1, 3)) %>% 
  pivot_longer(
    week_1:week_8,
    names_to = "week",
    values_to = "outcome",
    names_prefix = "week_") %>% 
  mutate(week = as.numeric(week)) %>% 
  select(group, subj = files, week, outcome)
```

Finally, the code chunk below creates a plot showing individual data,
faceted by group.

``` r
tidy_df %>% 
  ggplot(aes(x = week, y = outcome, group = subj, color = group)) + 
  geom_point() + 
  geom_path() + 
  facet_grid(~group)
```

<img src="p8105_hw5_yy3307_files/figure-gfm/unnamed-chunk-3-1.png" width="90%" />

This plot suggests high within-subject correlation – subjects who start
above average end up above average, and those that start below average
end up below average. Subjects in the control group generally don’t
change over time, but those in the experiment group increase their
outcome in a roughly linear way.

## Problem 2

First we need to import the `homicide` dataset and clean-up the variable
names.

``` r
homicide_raw = 
  read_csv("https://raw.githubusercontent.com/washingtonpost/data-homicides/master/homicide-data.csv") %>% 
  janitor::clean_names()
```

To describe raw data, we need some basic inline R code to generate some
info that we need.

``` r
raw_row = nrow(homicide_raw)
raw_col = ncol(homicide_raw)
```

The raw homicide dataset has 52179 rows and 12 columns, including main
variables of `reported_date`, victims’ information such as
`name, age, race, gender`, reported `city` and its corresponding
geographic location `lat, lon`, and cases’ `disposition`.

Then we want to analyze total number of homicides and unsolved homicides
in each city state. First we need to add a `city_state` variable as a
combination of the `city` and `state`. Then we can group the data by
`city_state` and count for number of total homicide and unsolved
homicide in each city state.

``` r
homicide_raw =
  homicide_raw %>% 
  mutate(
    city_state = str_c(city, ", ", state)
  )

homicide_count =
  homicide_raw %>%
  group_by(city_state) %>%
  summarize(
    total_homicide = n(),
    total_unsolved_homicide = sum(disposition == "Closed without arrest" | disposition == "Open/No arrest")
  )

homicide_count
```

    ## # A tibble: 51 × 3
    ##    city_state      total_homicide total_unsolved_homicide
    ##    <chr>                    <int>                   <int>
    ##  1 Albuquerque, NM            378                     146
    ##  2 Atlanta, GA                973                     373
    ##  3 Baltimore, MD             2827                    1825
    ##  4 Baton Rouge, LA            424                     196
    ##  5 Birmingham, AL             800                     347
    ##  6 Boston, MA                 614                     310
    ##  7 Buffalo, NY                521                     319
    ##  8 Charlotte, NC              687                     206
    ##  9 Chicago, IL               5535                    4073
    ## 10 Cincinnati, OH             694                     309
    ## # … with 41 more rows
